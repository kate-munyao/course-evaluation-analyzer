# Interpretation and Recommendations  
### Course Evaluation Analysis for BBT 4106 & BBT 4206
  
**Tools Used:** Python, scikit-learn, NLTK, Streamlit  
---

## 1. Summary of Findings

### 1.1 Main Topics Students Talked About  
Using LDA topic modelling, we found **5 key themes** in the evaluations:

---

### **Topic 1: Practical Labs and Hands-on Learning (46%)**
This was the most common topic (60 out of 130 comments). Students mostly talked about their lab experience.

**Why it stands out:**
- Labs are more engaging than theory.
- Students get to use real tools (Python, R, Power BI).
- It makes the course feel practical and useful.
- It is what makes BI different from many other units.

---

### **Topic 2: Learning Resources and Materials (35%)**  
About 45 comments focused on learning materials such as slides, notes, videos, and e-learning resources.

**Why it matters:**
Students depend heavily on these materials, so when they’re unclear or unhelpful, they notice quickly.

---

### **Topic 3: Course Content and Structure (15%)**  
20 comments focused on how the course is arranged and how topics flow.

**Common concerns:**
- Some topics moved too fast.
- Others felt like they needed more explanation.
- A few students had opinions on what should be added or removed.

---

### **Topic 4: Assessments and Feedback (8%)**  
15 comments mentioned assignments, quizzes, and grading.

**Why the percentage is low:**
Most students seemed okay with assessments unless something specific bothered them.

---

### **Topic 5: Teaching Quality and Engagement (2%)**  
Only 2 comments mentioned teaching style directly.

This is not a negative thing — students usually comment on teaching only when it is extremely good or extremely bad. Most of the teaching feedback appeared indirectly under other topics.

---

## 1.2 Sentiment for Each Topic

### **Practical Labs**
- **Positive:** 30%  
- **Neutral:** 55%  
- **Negative:** 15%  

Students generally like the labs. The negative comments came from students who:
- Felt rushed,
- Struggled with programming,
- Experienced technical issues.

---

### **Learning Materials**
- **Positive:** 15%  
- **Neutral:** 51%  
- **Negative:** 34%  

This is the **biggest issue**.  
Negative comments mentioned:
- Slides with too much text,
- Unclear videos,
- Not enough examples,
- Mismatch between materials and assessments.

---

### **Course Content and Structure**
- **Positive:** 40%  
- **Neutral:** 30%  
- **Negative:** 30%  

Mixed reactions. Students liked the overall content but felt some topics were either rushed or too dense.

---

### **Assessments and Feedback**
- **Positive:** 33%  
- **Neutral:** 47%  
- **Negative:** 20%  

Generally acceptable, but some students wanted:
- Faster grading,
- Clearer rubrics,
- More detailed feedback.

---

## 2. Recommendations

###  **1. Improve Learning Materials (Highest Priority)**  
Because of the high negative sentiment (34%), this should be the first thing to fix.

**Suggestions:**
- Simplify slides and avoid long paragraphs.
- Add more diagrams and code examples.
- Make videos shorter and more structured.
- Provide more example questions and practice work.

**Expected impact:**  
Better understanding, lower frustration, and improved performance.

---

###  **2. Maintain and Strengthen Practical Labs**  
Labs are the strongest part of the course.

**Suggestions:**
- Add slightly more lab time.
- Use more real datasets.
- Offer optional advanced tasks for fast learners.
- Record lab demonstrations for revision.

**Expected impact:**  
Higher engagement and more positive feedback.

---

###  **3. Improve Course Structure**
Some students felt the content flow could be clearer.

**Suggestions:**
- Provide a detailed week-by-week roadmap.
- Explain how all topics connect.
- Adjust pacing for difficult sections.
- Update content based on student comments.

---

###  **4. Enhance Feedback on Assessments**
20% negative means this can be improved but is not urgent.

**Suggestions:**
- Faster feedback turnaround.
- Post sample answers after deadlines.
- Use clear grading rubrics.
- Add comments showing how students can improve.

---

## 3. Recommended Priority Order

| Priority | Area | Issue | Recommendation | Timeline | Impact |
|---------|------|-------|----------------|----------|--------|
| **#1**  | Learning Materials | 34% negative | Improve slides, videos, examples | Before next semester | Very High |
| **#2** | Labs | Already strong | Add more depth, keep current style | Ongoing | Very High |
| **#3**  | Course Structure | 30% negative | Reorganize and clarify flow | Next academic year | Medium |
| **#4**  | Feedback | 20% negative | Faster and clearer grading | Immediate | Medium |

---

## 4. Conclusion

From the 130 evaluations, we learned that:

1. **Students love the lab sessions** — they are the strongest part of the course.  
2. **Learning materials need urgent improvement**, as this received the most negative comments.  
3. **Course content and assessments are generally acceptable**, but can be improved with clearer structure and faster feedback.  
4. These insights are fully based on real student data and machine learning analysis, not guesses.

Improving the areas above will make the BI units more effective, easier to understand, and more enjoyable for students.

---
